{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_file = sio.loadmat(\"eventrain.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cercano(x,y,z,n):\n",
    "    a=abs(x-n)\n",
    "    b=abs(y-n)\n",
    "    c=abs(z-n)\n",
    "    if(a<=b and a<=c):\n",
    "        return x\n",
    "    elif(b<=a and b <=c):\n",
    "        return y\n",
    "    else:\n",
    "        return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importancion de librerias y se carga el archivo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mat_file[\"trcoll\"][0][0] # is \"tecoll\" for testing set\n",
    "genFeat = data[0]   # Contextual features\n",
    "ffcoefs = data[3]   # Fisherface space\n",
    "faceGist = data[4]  # GIST features\n",
    "edad=data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la edad real en una variable y se mantienen 3 datos de entrenamiento por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "mask_data=np.random.rand(edad.shape[0]) < 0.30\n",
    "\n",
    "genF_train = genFeat[~mask_data]\n",
    "genF_test = genFeat[mask_data]\n",
    "\n",
    "ffcoefs_train = ffcoefs[~mask_data]\n",
    "ffcoefs_test = ffcoefs[mask_data]\n",
    "\n",
    "faceGist_train = faceGist[~mask_data]\n",
    "faceGist_test = faceGist[mask_data]\n",
    "\n",
    "edad_train = edad[~mask_data]\n",
    "edad_test = edad[mask_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan los datos para poder probar los modelos propuestos, se puede utilizar tambien eventest para probar en vez de separar como en este caso, pero de esta forma es mas facil probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "\n",
    "std.fit(genF_train)\n",
    "genF_train = std.transform(genF_train) \n",
    "genF_test = std.transform(genF_test)\n",
    "\n",
    "std.fit(ffcoefs_train)\n",
    "ffcoefs_train = std.transform(ffcoefs_train) \n",
    "ffcoefs_test = std.transform(ffcoefs_test)\n",
    "\n",
    "std.fit(faceGist_train)\n",
    "faceGist_train = std.transform(faceGist_train) \n",
    "faceGist_test = std.transform(faceGist_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estandarizaron las matrices de los datos obtenidos a mano para poder usarlos en un ajuste lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import random as random\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(genF_train, edad_train)\n",
    "\n",
    "edad_pred_train = model.predict(genF_train)\n",
    "edad_pred_test = model.predict(genF_test)\n",
    "\n",
    "residuales = list()\n",
    "for i in range(len(edad_pred_train)):\n",
    "    error = edad_train[i] - edad_pred_train[i]\n",
    "    residuales.append(error)\n",
    "#####################################################\n",
    "model2 = LinearRegression(fit_intercept=True)\n",
    "model2.fit(ffcoefs_train, edad_train)\n",
    "\n",
    "edad_pred_train2 = model2.predict(ffcoefs_train)\n",
    "edad_pred_test2 = model2.predict(ffcoefs_test)\n",
    "\n",
    "residuales2 = list()\n",
    "for i in range(len(edad_pred_train2)):\n",
    "    error = edad_train[i] - edad_pred_train2[i]\n",
    "    residuales2.append(error)\n",
    "\n",
    "###################################################\n",
    "    \n",
    "model3 = LinearRegression(fit_intercept=True)\n",
    "model3.fit(faceGist_train, edad_train)\n",
    "\n",
    "edad_pred_train3 = model3.predict(faceGist_train)\n",
    "edad_pred_test3 = model3.predict(faceGist_test)\n",
    "\n",
    "residuales3 = list()\n",
    "for i in range(len(edad_pred_train3)):\n",
    "    error = edad_train[i] - edad_pred_train3[i]\n",
    "    residuales3.append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pone a entrenar con los valores, creando 3 modelos distintos los cuales se tendran que relacionar de alguna forma entre si para la solucion final. Tambien se puede buscar una forma de relacionarlos desde antes. Tambien se guarda el error residual para un posterior analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.23917720808154\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(len(residuales)):\n",
    "    a=cercano(edad_pred_train[i],edad_pred_train2[i],edad_pred_train3[i],edad_train[i])\n",
    "    l.append(a)\n",
    "\n",
    "errorprom=error=mean_absolute_percentage_error(edad_train,l)\n",
    "print(errorprom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando los valores mas cercanos al teorico se tiene un error muy grande, lo que quiere decir que es un mal metodo de prediccion y modelo, se debe buscar otra forma de relacionar los datos para poder tener un estimador real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "final=[]\n",
    "for i in range(len(data)):\n",
    "    if(i==1 or i==8):\n",
    "        continue\n",
    "    separacion=data[i][~mask_data]\n",
    "    std.fit(separacion)\n",
    "    separacion=std.transform(separacion)\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(separacion, edad_train)\n",
    "    edad_pred=model.predict(separacion)\n",
    "    final.append(edad_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este intento se crea una lista final, en la cual se iran almacenando los vectores obtenidos de las predicciones. Cada uno de las matrices pasa por el proceso de estandarizacion y se pasa por un nuevo modelo de entrenamiento. Se salta el 1 y el 8 por representar valores no utiles de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=[]\n",
    "for i in range(len(edad_train)):\n",
    "    suma=final[0][i]+final[1][i]+final[2][i]+final[3][i]+final[4][i]+final[5][i]+final[6][i]+final[7][i]+final[8][i]\n",
    "    suma=suma/9\n",
    "    tf.append(suma[0])\n",
    "errorprom=error=mean_absolute_percentage_error(edad_train,tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la forma descrita se tiene un error aun mayor, esto pasa debido a que en ciertas matrices se tienen valores muy grandes en las predicciones, por lo que habria que sacarlos del algoritmo final al ser datos que generan ruido. En este metodo se trato de usar el promedio de las predicciones de las distintas matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mejor forma parece ser relacionar los datos desde antes de la union o utilizar otro modelo de prediccion. La otra opcion ya fue mencionada, utilizando lo pedido en el inciso m de la pregunta 1 se puede hacer seleccion de atributos para poder utilizar solo las matrices que aporten al problema, dejando fuera las que generan datos de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
